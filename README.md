# Predicting-Retracted-Papers
Dataset of retracted papers from the Retraction Watch database with a 1:1 corresponding valid paper.

This database is a curated subset from the Retraction Watch database snapshot of 2/15/25, a database that tracks papers that are retracted for fraud or error. A corresponding set of papers was extracted from Semantic Scholar that are valid papers in close cosine similarity to those from the Retraction Watch subset. In order to focus the domain of the papers, we only used papers available on PubMed, thereby restricting the analysis to biomedical, life sciences, and healthcare. The papers considered were further constrained to those published from 2001 to 2/15/25. 

The retraction_watch_abstract30_recent.csv file contains abstracts from retracted papers that were published between 2022 – 2025. The retraction_watch_abstract30_early.csv file contains abstracts from retracted papers that were published between 2001 – 2021. Column A of the .csv files contains a 1 to indicate retracted for fraud and a 0 to indicate retracted for error. As can be seen, the dataset is highly imbalanced with significantly more  abstracts from papers that were retracted for fraud. Column B of the .csv files contains a semicolon separated list of reasons tracked by the Retraction Watch database for why the paper was retracted. Column C contains the abstract itself. In curating this dataset, any abstract that included any form of the word “retract” (retract, Retract, retracted, Retracted, etc.) or “withdrawn” was dropped (i.e. does not appear in this dataset).

The temporal split between retraction_watch_abstract30_recent.csv and retraction_watch_abstract30_early.csv is due to the general availability of OpenAI’s text-embedding-3-small (the first widely popular version of ChatGPT) in September of 2021. This temporal holdout eliminates the concern that the Large Language Model (LLM) might have seen the retracted papers as part of its training, which could leak into the LLM embeddings.

For each abstract in the retraction_watch_abstract30_recent.csv and retraction_watch_abstract30_early.csv, a corresponding paper was found in Semantic Scholar that was in the top 20 closest in cosine similarity, with highest citation count used first. A check was made with Crossref and against the Retraction Watch database to make sure the paper that was found was valid (i.e. not retracted or withdrawn). Also, the corresponding paper found in Semantic Scholar could only be used once, and if it appeared in the corresponding paper list a second time, the next highest citation count paper was used. The sematic_scholar_abstract30_recent.csv contains abstracts from papers in the years 2022 - 2025 and semantic_scholar_abstract30_early.csv contains abstracts from papers in the years 2001 – 2021. Both are simpler than their counterparts and and contain only the abstracts.

The files have been split to facilitate a temporal holdout analysis. A cross validation analysis can also be pursued by concatenating the two retracted abstract files as well as concatenating the two valid abstract files. Pair-wise grouping should be done within folds so that the training model doesn’t see one of the abstracts (retracted or valid) and then the test would have an easier time identifying the corresponding abtract.
